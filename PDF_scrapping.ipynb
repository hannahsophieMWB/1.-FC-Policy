{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8yf4R01VeEV"
   },
   "source": [
    "# Willkommen!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59CrjG_pUXZC"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Imported from Google collab \n",
    "\n",
    "PROJECT FOR PDF SCRAPPING \n",
    "You can learn more about Google Colab here:\n",
    "https://colab.research.google.com/notebooks/intro.ipynb\n",
    "\n",
    "**Goal: Scrape unstructured legal text from public database and convert into xml readible format for further legal analysis**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zEDxy19TW_D"
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jWIGCwRPYws",
    "outputId": "ebc55624-384c-43d5-d8c6-5c4ee1008dbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.9/site-packages (1.26.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (1.2.4)\n",
      "Requirement already satisfied: as in /usr/local/lib/python3.9/site-packages (0.1)\n",
      "Requirement already satisfied: pd in /usr/local/lib/python3.9/site-packages (0.0.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.9/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.9/site-packages (0.5.28)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.9/site-packages (from pdfplumber) (8.1.2)\n",
      "Requirement already satisfied: pdfminer.six==20200517 in /usr/local/lib/python3.9/site-packages (from pdfplumber) (20200517)\n",
      "Requirement already satisfied: Wand in /usr/local/lib/python3.9/site-packages (from pdfplumber) (0.6.6)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.9/site-packages (from pdfminer.six==20200517->pdfplumber) (4.0.0)\n",
      "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.9/site-packages (from pdfminer.six==20200517->pdfplumber) (3.10.1)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.9/site-packages (from pdfminer.six==20200517->pdfplumber) (2.3.0)\n",
      "Requirement already satisfied: tabula-py in /usr/local/lib/python3.9/site-packages (2.2.0)\n",
      "Requirement already satisfied: distro in /usr/local/lib/python3.9/site-packages (from tabula-py) (1.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from tabula-py) (1.20.3)\n",
      "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.9/site-packages (from tabula-py) (1.2.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/site-packages (from pandas>=0.25.3->tabula-py) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/site-packages (from pandas>=0.25.3->tabula-py) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=0.25.3->tabula-py) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def restart_runtime():\n",
    "  os.kill(os.getpid(), 9)\n",
    "\n",
    "!pip3 install PyPDF2\n",
    "!pip3 install pandas as pd\n",
    "!pip3 install pdfplumber\n",
    "\n",
    "# Import the required Module\n",
    "!pip3 install tabula-py\n",
    "import tabula # for pdf \n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "# xml_exporter.py\n",
    "\n",
    "import re\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import collections\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikY03HV9WVFh"
   },
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlpUzEokz6RI"
   },
   "source": [
    "Mount the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rhNNrhKc8hZR",
    "outputId": "6c748ace-fca1-432f-c427-50508c9c5d6c"
   },
   "outputs": [],
   "source": [
    "\n",
    "# FOR GOOGLE COLLAB ONLY\n",
    "\n",
    "# accessing files in gdrive\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# % cd /gdrive\n",
    "\n",
    "# file path (you need to insert where you store the pdf\n",
    "# file_path = r'/gdrive/MyDrive/Women in Tech Mentorship 2021/Project #1 /Documents/Final Report on Guidelines on revised ML TF Risk Factors.pdf'\n",
    "\n",
    "\n",
    "\n",
    "# FOR JUPYTER NOTEBOOK\n",
    "from IPython.display import IFrame, display\n",
    "\n",
    "file_path = \"/Users/user/Python/Python projects/Final Report on Guidelines on revised ML TF Risk Factors.pdf\" # works with websites too!\n",
    "\n",
    "# IFrame(filepath, width=700, height=400)\" # works with websites too!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qc9qofsTKLeo"
   },
   "source": [
    "##  Conversion from pdf to xml for parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQ_tHzCzZjTM"
   },
   "source": [
    "1. Extract the pages for parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7-yht1dgHO2",
    "outputId": "bca45438-18b2-4543-afb6-ad0236b501f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL REPORT ON GUIDELINES ON CUSTOMER DUE DILIGENCE AND THE FACTORS CREDIT  \n",
      "AND FINANCIAL INSTITUTIONS SHOULD CONSIDER WHEN ASSESSING THE ML/TF RISK  \n",
      "ASSOCIATED WITH INDIVIDUAL BUSINESS RELATIONSHIPS AND OCCASIONAL TRANSACTIONS \n",
      "4.68.  Firms should note that the application of a risk-based approach does not of itself require \n",
      "them to refuse, or terminate, business relationships with entire categories of customers that \n",
      "they associate with higher ML/TF risk, as the risk associated with individual business \n",
      "relationships will vary, even within one category. \n",
      "Monitoring  \n",
      "4.69.  Pursuant to Article 13 of Directive (EU) 2015/849, firms should monitor their business \n",
      "relationships with their customers. \n",
      "4.70.  Monitoring should include: \n",
      "a.  Monitoring of transactions to ensure that these are in line with the customer’s \n",
      "risk profile, their financial situation, and the firm’s wider knowledge of the \n",
      "customer to detect unusual or suspicious transactions; and  \n",
      "b.  keeping the documents, data or information they hold up to date, with a view \n",
      "to understanding whether the risk associated with the business relationship \n",
      "has changed and to ascertain that the information that forms the basis for \n",
      "ongoing monitoring is accurate.  \n",
      "4.71.  Firms should determine the frequency and intensity of monitoring on a risk-sensitive basis, \n",
      "taking into account the nature, size and complexity of their business and the level of risk to \n",
      "which they are exposed.   \n",
      "Transaction monitoring \n",
      "4.72.  Firms  should  ensure  that  their  approach  to  transaction  monitoring  is  effective  and \n",
      "appropriate.  \n",
      "4.73.  An effective transaction monitoring system relies on up-to-date customer information and \n",
      "should  enable  the  firm  reliably  to  identify  unusual  and  suspicious  transactions  and \n",
      "transaction patterns. Firms should ensure that they have processes in place to review flagged \n",
      "transactions without undue delay. \n",
      "4.74.  What is appropriate will depend on the nature, size and complexity of the firm’s business, as \n",
      "well as the risk to which the firm is exposed. Firms should adjust the intensity and frequency \n",
      "of monitoring in line with the risk-based approach. Firms should in any case determine. \n",
      "a)  Which transactions they will monitor in real time, and which transactions they \n",
      "will monitor ex-post. As part of this, firms should determine: \n",
      "i.  which high-risk factors, or combination of high-risk factors, will \n",
      "always trigger real-time monitoring; and  \n",
      "55 \n",
      " \n",
      "FINAL REPORT ON GUIDELINES ON CUSTOMER DUE DILIGENCE AND THE FACTORS CREDIT  \n",
      "AND FINANCIAL INSTITUTIONS SHOULD CONSIDER WHEN ASSESSING THE ML/TF RISK  \n",
      "ASSOCIATED WITH INDIVIDUAL BUSINESS RELATIONSHIPS AND OCCASIONAL TRANSACTIONS \n",
      "4.68.  Firms should note that the application of a risk-based approach does not of itself require \n",
      "them to refuse, or terminate, business relationships with entire categories of customers that \n",
      "they associate with higher ML/TF risk, as the risk associated with individual business \n",
      "relationships will vary, even within one category. \n",
      "Monitoring  \n",
      "4.69.  Pursuant to Article 13 of Directive (EU) 2015/849, firms should monitor their business \n",
      "relationships with their customers. \n",
      "4.70.  Monitoring should include: \n",
      "a.  Monitoring of transactions to ensure that these are in line with the customer’s \n",
      "risk profile, their financial situation, and the firm’s wider knowledge of the \n",
      "customer to detect unusual or suspicious transactions; and  \n",
      "b.  keeping the documents, data or information they hold up to date, with a view \n",
      "to understanding whether the risk associated with the business relationship \n",
      "has changed and to ascertain that the information that forms the basis for \n",
      "ongoing monitoring is accurate.  \n",
      "4.71.  Firms should determine the frequency and intensity of monitoring on a risk-sensitive basis, \n",
      "taking into account the nature, size and complexity of their business and the level of risk to \n",
      "which they are exposed.   \n",
      "Transaction monitoring \n",
      "4.72.  Firms  should  ensure  that  their  approach  to  transaction  monitoring  is  effective  and \n",
      "appropriate.  \n",
      "4.73.  An effective transaction monitoring system relies on up-to-date customer information and \n",
      "should  enable  the  firm  reliably  to  identify  unusual  and  suspicious  transactions  and \n",
      "transaction patterns. Firms should ensure that they have processes in place to review flagged \n",
      "transactions without undue delay. \n",
      "4.74.  What is appropriate will depend on the nature, size and complexity of the firm’s business, as \n",
      "well as the risk to which the firm is exposed. Firms should adjust the intensity and frequency \n",
      "of monitoring in line with the risk-based approach. Firms should in any case determine. \n",
      "a)  Which transactions they will monitor in real time, and which transactions they \n",
      "will monitor ex-post. As part of this, firms should determine: \n",
      "i.  which high-risk factors, or combination of high-risk factors, will \n",
      "always trigger real-time monitoring; and  \n",
      "55 \n",
      " \n",
      "FINAL REPORT ON GUIDELINES ON CUSTOMER DUE DILIGENCE AND THE FACTORS CREDIT  \n",
      "AND FINANCIAL INSTITUTIONS SHOULD CONSIDER WHEN ASSESSING THE ML/TF RISK  \n",
      "ASSOCIATED WITH INDIVIDUAL BUSINESS RELATIONSHIPS AND OCCASIONAL TRANSACTIONS \n",
      "4.68.  Firms should note that the application of a risk-based approach does not of itself require \n",
      "them to refuse, or terminate, business relationships with entire categories of customers that \n",
      "they associate with higher ML/TF risk, as the risk associated with individual business \n",
      "relationships will vary, even within one category. \n",
      "Monitoring  \n",
      "4.69.  Pursuant to Article 13 of Directive (EU) 2015/849, firms should monitor their business \n",
      "relationships with their customers. \n",
      "4.70.  Monitoring should include: \n",
      "a.  Monitoring of transactions to ensure that these are in line with the customer’s \n",
      "risk profile, their financial situation, and the firm’s wider knowledge of the \n",
      "customer to detect unusual or suspicious transactions; and  \n",
      "b.  keeping the documents, data or information they hold up to date, with a view \n",
      "to understanding whether the risk associated with the business relationship \n",
      "has changed and to ascertain that the information that forms the basis for \n",
      "ongoing monitoring is accurate.  \n",
      "4.71.  Firms should determine the frequency and intensity of monitoring on a risk-sensitive basis, \n",
      "taking into account the nature, size and complexity of their business and the level of risk to \n",
      "which they are exposed.   \n",
      "Transaction monitoring \n",
      "4.72.  Firms  should  ensure  that  their  approach  to  transaction  monitoring  is  effective  and \n",
      "appropriate.  \n",
      "4.73.  An effective transaction monitoring system relies on up-to-date customer information and \n",
      "should  enable  the  firm  reliably  to  identify  unusual  and  suspicious  transactions  and \n",
      "transaction patterns. Firms should ensure that they have processes in place to review flagged \n",
      "transactions without undue delay. \n",
      "4.74.  What is appropriate will depend on the nature, size and complexity of the firm’s business, as \n",
      "well as the risk to which the firm is exposed. Firms should adjust the intensity and frequency \n",
      "of monitoring in line with the risk-based approach. Firms should in any case determine. \n",
      "a)  Which transactions they will monitor in real time, and which transactions they \n",
      "will monitor ex-post. As part of this, firms should determine: \n",
      "i.  which high-risk factors, or combination of high-risk factors, will \n",
      "always trigger real-time monitoring; and  \n",
      "55 \n",
      " \n",
      "225\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of pages\n",
    "total_pages = 3 # insert number of pages you want\n",
    "\n",
    "# create an empty dataframe\n",
    "dfs = []\n",
    "\n",
    "for page in range(total_pages):\n",
    "  with pdfplumber.open(file_path) as pdf:\n",
    "    test = pdf.pages[54] # replace the number 54 with \"page\" once the regex are fixed\n",
    "    test_text = test.extract_text()\n",
    "    #text_cleaned = test_text.replace('\\n', ' ')\n",
    "    print(test_text)\n",
    "\n",
    "totalpages = len(pdf.pages)\n",
    "print(totalpages)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWAaIarnZq8N"
   },
   "source": [
    "**2. Build Regex **\n",
    "\n",
    "NOTE: These need fixing for subletters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvvNpPSe7NsS",
    "outputId": "3c2d681b-68dc-4c00-eb0a-d33f2e252c31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Extracted text for Guidelines: ['4.68.', '4.69.', '4.70.', '4.71.', '4.72.', '4.73.', '4.74.']\n",
      "Extracted text for Guideline text: [' Firms should note that the application of a risk-based approach does not of itself require \\nthem to refuse, or terminate, business relationships with entire categories of customers that \\nthey associate with higher ML/TF risk, as the risk associated with individual business \\nrelationships will vary, even within one category. \\nMonitoring  ', ' Pursuant to Article 13 of Directive (EU) 2015/849, firms should monitor their business \\nrelationships with their customers. ', ' Monitoring should include: \\na.  Monitoring of transactions to ensure that these are in line with the customer’s \\nrisk profile, their financial situation, and the firm’s wider knowledge of the \\ncustomer to detect unusual or suspicious transactions; and  \\nb.  keeping the documents, data or information they hold up to date, with a view \\nto understanding whether the risk associated with the business relationship \\nhas changed and to ascertain that the information that forms the basis for \\nongoing monitoring is accurate.  ', ' Firms should determine the frequency and intensity of monitoring on a risk-sensitive basis, \\ntaking into account the nature, size and complexity of their business and the level of risk to \\nwhich they are exposed.   \\nTransaction monitoring ', ' Firms  should  ensure  that  their  approach  to  transaction  monitoring  is  effective  and \\nappropriate.  ', ' An effective transaction monitoring system relies on up-to-date customer information and \\nshould  enable  the  firm  reliably  to  identify  unusual  and  suspicious  transactions  and \\ntransaction patterns. Firms should ensure that they have processes in place to review flagged \\ntransactions without undue delay. ', ' What is appropriate will depend on the nature, size and complexity of the firm’s business, as \\nwell as the risk to which the firm is exposed. Firms should adjust the intensity and frequency \\nof monitoring in line with the risk-based approach. Firms should in any case determine. \\na)  Which transactions they will monitor in real time, and which transactions they \\nwill monitor ex-post. As part of this, firms should determine: \\ni.  which high-risk factors, or combination of high-risk factors, will \\nalways trigger real-time monitoring; and  \\n55 \\n ']\n",
      "Extracted Subletter: ['a.', 'b.', 'appropriate.', 'a)', 'i.']\n"
     ]
    }
   ],
   "source": [
    "# TEST REGEX ON PDF \n",
    "# Let's first replace the line breaks as the regex below can't handle line breaks. It's just easier to remove them first.\n",
    "#text_cleaned = text_cleaned.replace('\\n', ' ')\n",
    "text_cleaned  = test_text\n",
    "\n",
    "# I Sections \n",
    "\n",
    "Section_re = r'(Guideline) (\\d+\\:) (.*)'\n",
    "Sections = re.findall(Section_re, text_cleaned, re.IGNORECASE)\n",
    "# print(matches_group0)\n",
    "\n",
    "\n",
    "# 1. Paragraphs\n",
    "\n",
    "Paragraph_re = r'(\\d+\\.\\d+\\.)'\n",
    "Paragraphs = re.findall(Paragraph_re, text_cleaned, re.IGNORECASE)\n",
    "# print(matches_group1)\n",
    "\n",
    "# ## Text after paragraphs\n",
    "Paragraph_text_re = r'^\\d+(?:\\.\\d+)+\\. (.*(?:\\r?\\n(?!\\d+\\.).*)*)'\n",
    "Paragraph_text = re.findall(Paragraph_text_re, text_cleaned, re.MULTILINE)\n",
    "print(len(Paragraph_text))\n",
    "\n",
    "\n",
    "# a) Test for subletters specifically\n",
    "\n",
    "subletters_re = r'^(?:(?:\\d+(?:\\.)+|[a-zA-Z]+)[.)])'\n",
    "Subletters = re.findall(subletters_re, text_cleaned, re.MULTILINE)\n",
    "#print(Subletters)\n",
    "\n",
    "# a) text: Text after sub-letters \n",
    "subletters_text_re = r'^(?:(?:\\d+(?:\\.)+|[a-zA-Z]+)[.)]) (.*(?:\\r?\\n(?![a-zA-Z\\d]+[.)]).*)*)'\n",
    "Subletters_text = re.findall(subletters_text_re , text_cleaned, re.MULTILINE)\n",
    "# #print(Subletters_text)\n",
    "\n",
    "# # aa) Sub-sub letters\n",
    "# subsubletters_re = r'^[a-zA-Z\\s]{2}[\\.)]{1}'\n",
    "# subsubletters = re.findall(subsubletters_re, text_cleaned, re.MULTILINE)\n",
    "# #print(subsubletters)\n",
    "\n",
    "# # # aa): Text after sub-sub-letters \n",
    "# # subsubletters_text_re = r'[a-z][a-z]\\)'\n",
    "# # Subsubletters_text = re.findall(subsubletters_text_re, text_cleaned, re.MULTILINE)\n",
    "# # #print(Subsubletters_text)\n",
    "\n",
    "\n",
    "# # # a. Sub-letters 3rd degree\n",
    "# sub_point_re = r'^[a-zA-Z\\s]{3}[\\.)]{1}'\n",
    "# Subsubletters_point = re.findall(sub_point_re, text_cleaned, re.MULTILINE)\n",
    "# #print(Subsubletters_point)\n",
    "\n",
    "# # a.  Sub-letter text with point\n",
    "# sub_point_text_re = r'([A-z]\\.M{0,2}).*'\n",
    "# sub_point_text = re.findall(sub_point_text_re , text_cleaned, re.MULTILINE)\n",
    "# #print(sub_point_text)\n",
    "\n",
    "\n",
    "\n",
    "# # i.ii.iv Test for sub-strings\n",
    "\n",
    "# sub_letter_re = r'(?=\\b[MDCLXVI]+\\b)M{0,4}(?:CM|CD|D?C{0,3})(?:XC|XL|L?X{0,3})(?:IX|IV|V?I{0,3})'\n",
    "# Substrings = re.findall(sub_letter_re, text_cleaned,  re.IGNORECASE)\n",
    "# # print(matches_group5)\n",
    "\n",
    "# # Test 4.1:  sub-strings text\n",
    "# sub_letter_text_re = r'(?=\\b[MDCLXVI]+\\b)M{0,4}(?:CM|CD|D?C{0,3})(?:XC|XL|L?X{0,3})(?:IX|IV|V?I{0,3})(.*)'\n",
    "\n",
    "# Substrings_text = re.findall(sub_letter_text_re, text_cleaned ,  re.IGNORECASE)\n",
    "# # print(matches_group6)\n",
    "\n",
    "\n",
    "# PRINT\n",
    "\n",
    "# print(f\"Original text (whitout line breaks):{text_cleaned }\")\n",
    "# print(\"----------------------------------------\")\n",
    "print(f\"Extracted text for Guidelines: {Paragraphs }\")\n",
    "print(f\"Extracted text for Guideline text: {Paragraph_text }\")\n",
    "# # print(\"----------------------------------------\")\n",
    "# #--------------------\n",
    "print(f\"Extracted Subletter: {Subletters}\")\n",
    "# # print(f\"Extracted Subletters text: {Subletters_text}\")\n",
    "# print(\"----------------------------------------\")\n",
    "# #--------------------\n",
    "# print(f\"Extracted Sublsubetter: {subsubletters}\")\n",
    "# print(f\"Extracted Subsubletters text: {Subsubletters_text}\")\n",
    "# print(\"----------------------------------------\")\n",
    "#print(f\"Extracted Substrings: {Subsubletters_point}\")\n",
    "# print(f\"Extracted Substrings text: {Substrings_text}\")\n",
    "# print(\"----------------------------------------\")\n",
    "# #--------------------\n",
    "#print(f\"Extracted  Sub-letter with point : {Subsubletters_point}\")\n",
    "# print(f\"Extracted  Sub-letter text with point : {sub_point_text}\")\n",
    "\n",
    "\n",
    "# NEXT STEPS\n",
    "# transform expression \n",
    "# def my_function(text):\n",
    "        # return \"something\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, Paragraph                                                4.68.\n",
      "Wording       Firms should note that the application of a r...\n",
      "Name: 2, dtype: object)\n",
      "(2, Paragraph                                                4.69.\n",
      "Wording       Pursuant to Article 13 of Directive (EU) 2015...\n",
      "Name: 2, dtype: object)\n",
      "(2, Paragraph                                                4.70.\n",
      "Wording       Monitoring should include: \\na.  Monitoring o...\n",
      "Name: 2, dtype: object)\n",
      "(2, Paragraph                                                4.71.\n",
      "Wording       Firms should determine the frequency and inte...\n",
      "Name: 2, dtype: object)\n",
      "(2, Paragraph                                                4.72.\n",
      "Wording       Firms  should  ensure  that  their  approach ...\n",
      "Name: 2, dtype: object)\n",
      "(2, Paragraph                                                4.73.\n",
      "Wording       An effective transaction monitoring system re...\n",
      "Name: 2, dtype: object)\n",
      "(2, Paragraph                                                4.74.\n",
      "Wording       What is appropriate will depend on the nature...\n",
      "Name: 2, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "total_pages = 3 # insert number of pages you want\n",
    "\n",
    "\n",
    "# create an empty dataframe\n",
    "dfs = []\n",
    "\n",
    "# for page in range(total_pages):\n",
    "#   with pdfplumber.open(file_path) as pdf:\n",
    "#     test = pdf.pages[54] # replace the number 54 with \"page\" once the regex are fixed\n",
    "#     test_text = test.extract_text()\n",
    "#     text_cleaned = test_text.replace('\\n', ' ')\n",
    "    \n",
    "    # ---- Insert all your regex here ---\n",
    "\n",
    "    ### Steps\n",
    "    # 1. Paste your REGEX\n",
    "    # 2. Create an empty list eg df_temp = []\n",
    "    # 3. Iterate over the text and paragraph\n",
    "    # 4. Append to a dict object\n",
    "    # 5. Append to the the list you created in step 2\n",
    "    # 6. Create a dataframe and set index to page number\n",
    "\n",
    "# Paragraph\n",
    "\n",
    "df1_temp =[]\n",
    "for text, paragraph in zip(Paragraph_text, Paragraphs ): \n",
    "    item = {}\n",
    "    item[\"page_number\"] = page\n",
    "    item[\"Paragraph\"] = paragraph    \n",
    "    item[\"Wording\"] = text\n",
    "      \n",
    "    df1_temp.append(item)\n",
    "  \n",
    "   \n",
    "    df1 = pd.DataFrame(df1_temp).set_index(\"page_number\")\n",
    "\n",
    "#print(df1)\n",
    "\n",
    "# For Loop\n",
    "for  column in  df1.iterrows():\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# ### FINAL STEP - aggregate everything    \n",
    "# # # Example: pd.concat([df1, df2, df3,....], axis=1)\n",
    "# # df_final = pd.concat([df1, df2], axis=1)\n",
    "# # df_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach B: more computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-04b4000bcdfb>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-04b4000bcdfb>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    3.1 Write For Loop to parse through the list of Regex\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "3.1 Write For Loop to parse through the list of Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fLCmWVHmImJj",
    "outputId": "1ce90887-493b-4c45-a546-77a84297a348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Paragraph     Subletter  \\\n",
      "page_number                           \n",
      "<Page:77>       4.68.            a.   \n",
      "<Page:77>       4.68.            b.   \n",
      "<Page:77>       4.68.  appropriate.   \n",
      "<Page:77>       4.68.            a)   \n",
      "<Page:77>       4.68.            i.   \n",
      "<Page:77>       4.68.            []   \n",
      "<Page:77>       4.69.            a.   \n",
      "<Page:77>       4.69.            b.   \n",
      "<Page:77>       4.69.  appropriate.   \n",
      "<Page:77>       4.69.            a)   \n",
      "<Page:77>       4.69.            i.   \n",
      "<Page:77>       4.69.            []   \n",
      "<Page:77>       4.70.            a.   \n",
      "<Page:77>       4.70.            b.   \n",
      "<Page:77>       4.70.  appropriate.   \n",
      "<Page:77>       4.70.            a)   \n",
      "<Page:77>       4.70.            i.   \n",
      "<Page:77>       4.70.            []   \n",
      "<Page:77>       4.71.            a.   \n",
      "<Page:77>       4.71.            b.   \n",
      "<Page:77>       4.71.  appropriate.   \n",
      "<Page:77>       4.71.            a)   \n",
      "<Page:77>       4.71.            i.   \n",
      "<Page:77>       4.71.            []   \n",
      "<Page:77>       4.72.            []   \n",
      "<Page:77>       4.73.            []   \n",
      "<Page:77>       4.74.            []   \n",
      "\n",
      "                                                       Wording  \n",
      "page_number                                                     \n",
      "<Page:77>      Monitoring of transactions to ensure that th...  \n",
      "<Page:77>                                                       \n",
      "<Page:77>                                                       \n",
      "<Page:77>                                                       \n",
      "<Page:77>                                                       \n",
      "<Page:77>      Firms should note that the application of a ...  \n",
      "<Page:77>      Monitoring of transactions to ensure that th...  \n",
      "<Page:77>      keeping the documents, data or information t...  \n",
      "<Page:77>                                                       \n",
      "<Page:77>                                                       \n",
      "<Page:77>                                                       \n",
      "<Page:77>      Pursuant to Article 13 of Directive (EU) 201...  \n",
      "<Page:77>      Monitoring of transactions to ensure that th...  \n",
      "<Page:77>      keeping the documents, data or information t...  \n",
      "<Page:77>      \\n4.73.  An effective transaction monitoring...  \n",
      "<Page:77>                                                       \n",
      "<Page:77>                                                       \n",
      "<Page:77>      Monitoring should include: \\na.  Monitoring ...  \n",
      "<Page:77>      Monitoring of transactions to ensure that th...  \n",
      "<Page:77>      keeping the documents, data or information t...  \n",
      "<Page:77>      \\n4.73.  An effective transaction monitoring...  \n",
      "<Page:77>      Which transactions they will monitor in real...  \n",
      "<Page:77>                                                       \n",
      "<Page:77>      Firms should determine the frequency and int...  \n",
      "<Page:77>      Firms  should  ensure  that  their  approach...  \n",
      "<Page:77>      An effective transaction monitoring system r...  \n",
      "<Page:77>      An effective transaction monitoring system r...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create a dataframe \n",
    "data = [ ]\n",
    "page_number = pdf.pages[76] \n",
    "\n",
    "# For Loop\n",
    "for index, para in enumerate(Paragraphs):\n",
    "\n",
    "  # for paragraphs\n",
    "  if (index + 1 < len(Paragraphs)):\n",
    "    #print (Paragraphs[index])\n",
    "    #print (Paragraphs[index + 1])\n",
    "    ind1 = text_cleaned.index(para)\n",
    "    ind2 = text_cleaned.index(Paragraphs[index + 1])\n",
    "    #print(ind1, ind2)\n",
    "    res = text_cleaned[ind1 + len(para) : ind2]\n",
    "\n",
    "  # for subletters\n",
    "  for idex1, subletter in enumerate(Subletters):\n",
    "    if (index + 1 < len(Subletters)):\n",
    "      ind3 = text_cleaned.index(subletter)\n",
    "      ind4 = text_cleaned.index(Subletters[index + 1])\n",
    "    #print(ind1, ind2)\n",
    "      res2 = text_cleaned[ind3 + len(subletter) : ind4]\n",
    "\n",
    "      item = {}\n",
    "      item[\"page_number\"] = page_number\n",
    "      item[\"Paragraph\"] = para \n",
    "      item[\"Subletter\"]  = subletter\n",
    "      item[\"Wording\"] = res2\n",
    "      data.append(item)\n",
    "    \n",
    "\n",
    "\n",
    "  item = {}\n",
    "  item[\"page_number\"] = page_number\n",
    "  item[\"Paragraph\"] = para \n",
    "  item[\"Subletter\"]  = []\n",
    "  item[\"Wording\"] = res\n",
    "\n",
    "\n",
    " # item.setdefault(\"Wording\", []).append(res2)\n",
    "\n",
    "  #d1.setdefault(key, []).append(value)\n",
    "\n",
    "\n",
    "  data.append(item)\n",
    "#print(data)\n",
    "  \n",
    "\n",
    "dataframe1 = pd.DataFrame(data).set_index(\"page_number\")\n",
    "print(dataframe1)\n",
    "#print(item)\n",
    "\n",
    "\n",
    "\n",
    "#print(dataframe1[[\"Subletter\", \"Wording\"]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7_Fz31FbUTT"
   },
   "source": [
    "# Old attemps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-G31sO9gATT"
   },
   "source": [
    "Size seemed to be a problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohDT_tgMgHUV"
   },
   "source": [
    "Here is an example of how you could append all the lists having as a reference the page number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "jwo-l1nEgP9N",
    "outputId": "5fb23fe4-2700-4e6f-f50b-31a95558b9d7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8144acd1e44b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m#df1 = pd.DataFrame(df1_temp).set_index(\"page_number\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "total_pages = 3 # insert number of pages you want\n",
    "\n",
    "\n",
    "# create an empty dataframe\n",
    "dfs = []\n",
    "\n",
    "for page in range(total_pages):\n",
    "  with pdfplumber.open(file_path) as pdf:\n",
    "    test = pdf.pages[54] # replace the number 54 with \"page\" once the regex are fixed\n",
    "    test_text = test.extract_text()\n",
    "    text_cleaned = test_text.replace('\\n', ' ')\n",
    "    \n",
    "    # ---- Insert all your regex here ---\n",
    "\n",
    "    ### Steps\n",
    "    # 1. Paste your REGEX\n",
    "    # 2. Create an empty list eg df_temp = []\n",
    "    # 3. Iterate over the text and paragraph\n",
    "    # 4. Append to a dict object\n",
    "    # 5. Append to the the list you created in step 2\n",
    "    # 6. Create a dataframe and set index to page number\n",
    "\n",
    "\n",
    "\n",
    "  # for loop to go per regex\n",
    "df1_temp =[]\n",
    "for text, paragraph in zip(Paragraph_text, Paragraphs ): # you sholdn't be insert the number - it should match\n",
    "    item = {}\n",
    "    item[\"page_number\"] = page\n",
    "    item[\"Paragraph\"] = paragraph    \n",
    "    item[\"Wording\"] = text\n",
    "      \n",
    "    df1_temp.append(item)\n",
    "  \n",
    "   \n",
    "    #df1 = pd.DataFrame(df1_temp).set_index(\"page_number\")\n",
    "\n",
    "print(df1)\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "f2OPNs3ZGCX5",
    "outputId": "67e11cb2-b496-471a-dd62-9e2174b36942"
   },
   "outputs": [],
   "source": [
    "\n",
    "    ### EXAMPLE 2\n",
    "\n",
    "    # a) Test for subletters specifically\n",
    "subletters_re = r'[a-z]\\){1,2}'\n",
    "Subletters = re.findall(subletters_re, text_cleaned, re.MULTILINE)\n",
    "    #print(Subletters)\n",
    "\n",
    "    # a) text: Text after sub-letters \n",
    "subletters_text_re = r'[a-zA-Z]\\)(.*)'\n",
    "Subletters_text = re.findall(subletters_text_re , text_cleaned, re.MULTILINE)\n",
    "\n",
    "df2_temp =[]\n",
    "for text2, paragraph2 in zip(Subletters, Subletters_text ): # you sholdn't be insert the number - it should match\n",
    "    item = {}\n",
    "    item[\"page_number\"] = page\n",
    "    item[\"Paragraph2\"] = paragraph2\n",
    "    item[\"Wording2\"] = text2\n",
    "\n",
    "    df2_temp.append(item)\n",
    "\n",
    "df2 = pd.DataFrame(df2_temp).set_index(\"page_number\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### FINAL STEP - aggregate everything    \n",
    "# Example: pd.concat([df1, df2, df3,....], axis=1)\n",
    "df_final = pd.concat([df1, df2], axis=1)\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yiYZGiiGCOq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3AwnogivUPJJ"
   },
   "outputs": [],
   "source": [
    "**OLD STUFF**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "lEU-XWfC-3sQ",
    "outputId": "c0a1f3e7-2d66-4569-bbfb-13a8f0585e1b"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# read pdf\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "Paragraph = []\n",
    "# total_check = 0 \n",
    "# use extend instead of append \n",
    "# use pandas \n",
    "# create a series based on ID\n",
    "\n",
    "# for paragraph in matches_group1:\n",
    "\n",
    "print(matches_group1)\n",
    "\n",
    "\n",
    "# needs adjustment to match my pdf\n",
    "with pdfplumber.open(EBA) as pdf:\n",
    "    pages = pdf.pages\n",
    "    for page in pdf.pages:\n",
    "        text = page.extract_text()\n",
    "        for line in text.split('\\n'):\n",
    "            print(line)\n",
    "            comp = company_re.search(line)\n",
    "            if comp:\n",
    "                vend_no, vend_name = comp.group(1), comp.group(2)\n",
    "\n",
    "            elif line.startswith('INVOICES'):\n",
    "                doctype = 'INVOICE'\n",
    "\n",
    "            elif line.startswith('CREDITNOTES'):\n",
    "                doctype = 'CREDITNOTE'\n",
    "\n",
    "            elif line_re.search(line):\n",
    "                items = line.split()\n",
    "                lines.append(Line(vend_no, vend_name, doctype, *items))\n",
    "                \n",
    "            elif line.startswith('Supplier total'):\n",
    "                tot = float(line.split()[2].replace(',', ''))\n",
    "                total_check += tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiVGMk0wEMoj"
   },
   "source": [
    "solution from https://www.youtube.com/watch?v=syEfR1QIGcY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqy-rqD58gB0"
   },
   "source": [
    "**OLD Codes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y96S-VrCU83J"
   },
   "source": [
    "##Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "GNpoA2HECe9n",
    "outputId": "d8dae561-1994-4c03-e917-8d983de7db39"
   },
   "outputs": [],
   "source": [
    "# create a series using pandas\n",
    "pd.Series(Paragraphs)\n",
    "\n",
    "# create a dataframe with pandas \n",
    "\n",
    "df = pd.DataFrame(Paragraph_text, Paragraphs[0:6] )\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df.columns = [\"Paragraph\", \"Wording\"]\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "# print(matches_group1)\n",
    "\n",
    "# how to deal with differences in length of axes \n",
    "# concatenation on common attribute (ie. pagenumber)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojFku79nVUSM",
    "outputId": "33ea436a-848d-497e-b463-e35bfd7a1fe4"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOgQRfSVVErM"
   },
   "source": [
    "**Q. loading pip3 install**\n",
    "\n",
    "A. You mentioned you had some trouble with pip3. Pip is a way to install python libraries, pip3 refers to python version 3. If you're having issues, double check you have python version 3 installed. Python version 2 is deprecated so you should not use it anymore. However, in many cases, you have it by default.\n",
    "You can do it by openning a new terminal window on your computer and write the command  `python --version` such as below:\n",
    "(Note that I added the special command `%% bash` to simulate a terminal, but you don't need that). Feel free to also paste the erros messages you're having here so it makes easier to find out why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVw2NQmDNVTf"
   },
   "source": [
    "**OLD** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCmlqQMM8h_i"
   },
   "outputs": [],
   "source": [
    "# creating a pdf file object \n",
    "file_path = r'/gdrive/MyDrive/Women in Tech Mentorship 2021/Project #1 /Documents/Final Report on Guidelines on revised ML TF Risk Factors.pdf'\n",
    "EBA = open(file_path, 'rb') \n",
    "  \n",
    "# creating a pdf reader object \n",
    "pdfReader = PyPDF2.PdfFileReader(EBA) \n",
    "  \n",
    "# printing number of pages in pdf file \n",
    "print(pdfReader.numPages) \n",
    "  \n",
    "# creating a page object \n",
    "pageObj = pdfReader.getPage(67) \n",
    "  \n",
    "# extracting text from page \n",
    "print(pageObj.extractText()) \n",
    "  \n",
    "# closing the pdf file object \n",
    "EBA.close() \n",
    "# remember to close later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCBWd3ki1zaP",
    "outputId": "157d74b3-34b5-436e-ebcf-83a3549669ba"
   },
   "outputs": [],
   "source": [
    "# Find new library \n",
    "\n",
    "EBA1 = open(file_path, 'rb') \n",
    "  \n",
    "# creating a pdf reader object \n",
    "pdfReader = PyPDF2.PdfFileReader(EBA1) \n",
    "  \n",
    "# printing number of pages in pdf file \n",
    "# print(pdfReader.numPages) \n",
    "  \n",
    "# creating a page object \n",
    "pageObj = pdfReader.getPage(76) \n",
    "  \n",
    "# extracting text from page \n",
    "# print(pageObj.extractText()) \n",
    "\n",
    "str_page_Obj = str(pageObj.extractText())\n",
    "print(str_page_Obj)\n",
    "\n",
    "\n",
    "# split: with dot is fine \n",
    "\n",
    "# PROBLEM: Does not extract the numbers before the text, ie a) \n",
    "# Try different library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0kFGw9sBNFfC",
    "outputId": "48832d1b-7118-485b-e59e-03f756b98251"
   },
   "outputs": [],
   "source": [
    "\"\"\n",
    "\n",
    "text0 = \"\"\"\n",
    "\n",
    "Guideline 9: Sectoral guideline for retail banks\n",
    "9.1. For the purpose of these guidelines, retail banking means the provision of banking services\n",
    "to natural persons and small and medium-sized enterprises. Examples of retail banking\n",
    "products and services include current accounts, mortgages, savings accounts, consumer and\n",
    "term loans, and credit lines.\n",
    "\n",
    "9.2. adfaadfafafsdf adfadfafas\n",
    "9.3. The following factor may contribute to reducing risk:\n",
    "9.6. The following factors may contribute to increasing risk\n",
    "a) The nature of the customer, for example:\n",
    "aa) The customer is a cash-intensive undertaking.\n",
    "\n",
    "12.1 ad; \n",
    "\n",
    "Guideline 10: haha this is a test\n",
    "a) The following factors may contribute to increasing risk:\n",
    "aa) test\n",
    "aaa) test1\n",
    "b) the product’s features favour anonymity;\n",
    "c) the product allows payments from third parties that are neither associated\n",
    "with the product nor identified upfront, where such payments would not be\n",
    "expected, for example for mortgages or loans;\n",
    "d) the product places no restrictions on turnover, cross-border transactions or\n",
    "similar product features;\n",
    "e) new products and new business practices, including new delivery mechanisms,\n",
    "and the use of new or developing technologies for both new and existing\n",
    "products where these are not yet well understood;\n",
    "f) lending (including mortgages) secured against the value of assets in other\n",
    "jurisdictions, particularly countries where it is difficult to ascertain whether the\n",
    "customer has legitimate title to the collateral, or where the identities of parties\n",
    "guaranteeing the loan are hard to verify;\n",
    "g) an unusually high volume or large value of transactions\n",
    "\n",
    "ii. The regulator states that xyz \n",
    "iii. Also the Risk Factor Blabla ;\n",
    "iv. adaf\n",
    "v. ddd\n",
    "vi. test \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Let's first replace the line breaks as the regex below can't handle line breaks. It's just easier to remove them first.\n",
    "text_cleaned = text0.replace('\\n', ' ')\n",
    "\n",
    "# Sections\n",
    "Section_re = r'(Guideline) (\\d+\\:) (.*)'\n",
    "\n",
    "Sections = re.findall(Section_re, text_cleaned, re.IGNORECASE)\n",
    "# print(matches_group0)\n",
    "\n",
    "\n",
    "# Test 2 Paragraphs\n",
    "\n",
    "Paragraph_re = r'(\\d+\\.\\d+\\.)'\n",
    "Paragraphs = re.findall(Paragraph_re, text_cleaned, re.IGNORECASE)\n",
    "# print(matches_group1)\n",
    "\n",
    "## Text after paragraphs\n",
    "Paragraph_text_re = r'(?<=\\n\\d\\.\\d\\.) [\\w+\\W*]*?(?=\\r?\\d\\.\\d\\.*)'\n",
    "Paragraph_text = re.findall(Paragraph_text_re, text_cleaned, re.IGNORECASE)\n",
    "# print(matches_group2)\n",
    "\n",
    "\n",
    "# TEST 3 Sub-letters\n",
    "\n",
    "subletters_re = r'([A-z]\\))'\n",
    "Subletters = re.findall(subletters_re, text_cleaned, re.IGNORECASE)\n",
    "# print(matches_group3)\n",
    "\n",
    "# Text afte sub-letters \n",
    "\n",
    "# This regex with match any letters capitalised or not and then everything that goes after that\n",
    "subletters_text_re = r'[a-zA-Z]\\)(.*)'\n",
    "Subletters_text = re.findall(subletters_text_re , text_cleaned, re.IGNORECASE)\n",
    "\n",
    "# TEST 4 sub-strings\n",
    "\n",
    "sub_letter_re = r'(?=\\b[MDCLXVI]+\\b)M{0,4}(?:CM|CD|D?C{0,3})(?:XC|XL|L?X{0,3})(?:IX|IV|V?I{0,3})'\n",
    "Substrings = re.findall(sub_letter_re, text_cleaned,  re.IGNORECASE)\n",
    "# print(matches_group5)\n",
    "\n",
    "# Test 4.1:  sub-strings text\n",
    "\n",
    "\n",
    "sub_letter_text_re = r'(?=\\b[MDCLXVI]+\\b)M{0,4}(?:CM|CD|D?C{0,3})(?:XC|XL|L?X{0,3})(?:IX|IV|V?I{0,3})(.*)'\n",
    "\n",
    "Substrings_text = re.findall(sub_letter_text_re, text_cleaned ,  re.IGNORECASE)\n",
    "# print(matches_group6)\n",
    "\n",
    "\n",
    "# PRINT\n",
    "\n",
    "print(f\"Original text (whitout line breaks): {text_cleaned}\")\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "print(f\"Extracted text for Sections: {Sections }\")\n",
    "print(f\"Extracted text for Guidelines: {Paragraphs }\")\n",
    "print(f\"Extracted text for Guideline text: {Paragraph_text }\")\n",
    "print(f\"Extracted Subletter: {Subletters}\")\n",
    "print(f\"Extracted Subletters text: {Subletters_text}\")\n",
    "print(f\"Extracted Substrings: {Substrings}\")\n",
    "print(f\"Extracted Substrings text: {Substrings_text}\")\n",
    "\n",
    "\n",
    "\n",
    "#  a) Sub-Letters\n",
    "\n",
    "subletters_re = r'[a-zA-Z]\\){1,2}'\n",
    "Subletters = re.findall(subletters_re, text_cleaned, re.IGNORECASE)\n",
    "# print(matches_group3)\n",
    "\n",
    "# Text after sub-letters \n",
    "\n",
    "# This regex with match any letters capitalised or not and then everything that goes after that\n",
    "subletters_text_re = r'[a-zA-Z]\\)(.*)'\n",
    "Subletters_text = re.findall(subletters_text_re , text_cleaned, re.IGNORECASE)\n",
    "\n",
    "# aa) Sub-sub letters\n",
    "subsubletters_re = r'[a-zA-Z]\\){1,3}'\n",
    "subsubletters = re.findall(subsubletters_re, text_cleaned, re.IGNORECASE)\n",
    "# print(matches_group3)\n",
    "\n",
    "# Text after sub-sub-letters \n",
    "\n",
    "# This regex with match any letters capitalised or not and then everything that goes after that\n",
    "subsubletters_text_re = r'([A-z][A-z]\\)M{0,2})(.*)'\n",
    "Subsubletters_text = re.findall(subsubletters_text_re, text_cleaned, re.IGNORECASE)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zf1JCFhpMdp_",
    "outputId": "ef80f804-3eb8-480f-8cc3-b1dc7630df27"
   },
   "outputs": [],
   "source": [
    "# EBA = pdfplumber.open(file_path)\n",
    "# page = EBA.pages[100]\n",
    "# text = page.extract_text()\n",
    "# text\n",
    "# print(text)\n",
    "\n",
    "# get a single page\n",
    "\n",
    "with pdfplumber.open(file_path) as pdf:\n",
    "  test = pdf.pages[54]\n",
    "  test_text = test.extract_text()\n",
    "  print(test_text)  \n",
    "\n",
    "# for all pages\n",
    "  #for pdf_page in pdf.pages:\n",
    "    #single_page_text = pdf_page.extract_text()\n",
    "    # print( single_page_text )\n",
    "   # print(pdf.pages[67])\n",
    "# print(single_page_text)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FINAL_Extract text data from pdf.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
